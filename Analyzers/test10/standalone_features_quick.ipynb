{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble (system)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "  raise AssertionError('Please run this notebook with Python 3.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble (EMTF)\n",
    "import numpy as np\n",
    "\n",
    "from emtf_algos import *\n",
    "from emtf_logger import get_logger\n",
    "from emtf_colormap import get_colormap\n",
    "\n",
    "# Preamble (notebook)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import itertools\n",
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw      : CMSSW_10_6_3\n",
      "[INFO    ] Using python     : 3.6.10 |Anaconda, Inc.| (default, Mar 25 2020, 23:51:54) [GCC 7.3.0]\n",
      "[INFO    ] Using numpy      : 1.19.5\n",
      "[INFO    ] Using matplotlib : 3.3.2\n",
      "[INFO    ] Using tensorflow : 2.4.1\n",
      "[INFO    ] Using keras      : 2.4.0\n",
      "[INFO    ] .. list devices  : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO    ] Using dask       : 2021.01.1\n",
      "[INFO    ] Using emtf-nnet  : 0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Preamble (ML)\n",
    "np.random.seed(2027)  # set random seed\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2027)  # set random seed\n",
    "\n",
    "#import numba\n",
    "#from numba import njit, vectorize\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "try:\n",
    "  import emtf_nnet\n",
    "except:\n",
    "  raise ImportError('This notebook requires emtf_nnet. It can be found at '\n",
    "                    'https://github.com/jiafulow/emtf-nnet')\n",
    "\n",
    "logger = get_logger()\n",
    "logger.info('Using cmssw      : {}'.format(os.environ.get('CMSSW_VERSION', 'n/a')))\n",
    "logger.info('Using python     : {}'.format(sys.version.replace('\\n', '')))\n",
    "logger.info('Using numpy      : {}'.format(np.__version__))\n",
    "logger.info('Using matplotlib : {}'.format(matplotlib.__version__))\n",
    "logger.info('Using tensorflow : {}'.format(tf.__version__))\n",
    "logger.info('Using keras      : {}'.format(tf.keras.__version__))\n",
    "logger.info('.. list devices  : {}'.format(tf.config.list_physical_devices()))\n",
    "#logger.info('Using numba      : {}'.format(numba.__version__))\n",
    "logger.info('Using dask       : {}'.format(dask.__version__))\n",
    "logger.info('Using emtf-nnet  : {}'.format(emtf_nnet.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Processing zone 0 timezone 0\n",
      "[INFO    ] .. maxevents        : 50\n",
      "[INFO    ] .. workers          : 8\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# zone: (0,1,2) -> eta=(1.98..2.5, 1.55..1.98, 1.2..1.55)\n",
    "zone = 0\n",
    "#zone = 1\n",
    "#zone = 2\n",
    "\n",
    "# timezone: (0,1,2) -> BX=(0,-1,-2)\n",
    "timezone = 0\n",
    "\n",
    "maxevents = 50\n",
    "#maxevents = -1\n",
    "\n",
    "#workers = 1\n",
    "workers = 8\n",
    "\n",
    "# Input files\n",
    "signal_fname = 'signal_add.20210112.npz'\n",
    "signal_displ_fname = 'signal_displ_add.20210112.npz'\n",
    "bkgnd_fname = 'bkgnd_add.20200716.npz'\n",
    "\n",
    "patterns_fname = 'patterns_zone%i.npz' % zone\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "dask.config.set(scheduler='threads', num_workers=workers)\n",
    "\n",
    "# Styling\n",
    "plt.style.use('tdrstyle.mplstyle')\n",
    "cm = get_colormap()\n",
    "\n",
    "logger.info('Processing zone {} timezone {}'.format(zone, timezone))\n",
    "logger.info('.. maxevents        : {}'.format(maxevents))\n",
    "logger.info('.. workers          : {}'.format(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal():\n",
    "  logger.info('Loading from {0}'.format(signal_fname))\n",
    "  with np.load(signal_fname) as loaded:\n",
    "    out_part = loaded['out_part']\n",
    "    out_hits_values = loaded['out_hits_values']\n",
    "    out_hits_row_splits = loaded['out_hits_row_splits']\n",
    "    out_hits_shape = (out_hits_row_splits.shape[0] - 1,) + (None,) + out_hits_values.shape[1:]\n",
    "    out_simhits_values = loaded['out_simhits_values']\n",
    "    out_simhits_row_splits = loaded['out_simhits_row_splits']\n",
    "    out_simhits_shape = (out_simhits_row_splits.shape[0] - 1,) + (None,) + out_simhits_values.shape[1:]\n",
    "    logger.info('out_part: {} out_hits: {} out_simhits: {}'.format(\n",
    "        out_part.shape, out_hits_shape, out_simhits_shape))\n",
    "  return (out_part, (out_hits_values, out_hits_row_splits), (out_simhits_values, out_simhits_row_splits))\n",
    "\n",
    "\n",
    "def load_bkgnd():\n",
    "  logger.info('Loading from {0}'.format(bkgnd_fname))\n",
    "  with np.load(bkgnd_fname) as loaded:\n",
    "    out_bkg_aux = loaded['out_aux']\n",
    "    out_bkg_hits_values = loaded['out_hits_values']\n",
    "    out_bkg_hits_row_splits = loaded['out_hits_row_splits']\n",
    "    out_bkg_hits_shape = (out_bkg_hits_row_splits.shape[0] - 1,) + (None,) + out_bkg_hits_values.shape[1:]\n",
    "    logger.info('out_bkg_aux: {} out_bkg_hits: {}'.format(out_bkg_aux.shape, out_bkg_hits_shape))\n",
    "  return (out_bkg_aux, (out_bkg_hits_values, out_bkg_hits_row_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternHelper(object):\n",
    "  \"\"\"Reshapes patterns for use in NN.\"\"\"\n",
    "  def get_reshaped_patterns(self, patterns):\n",
    "    patterns = patterns[3]  # prompt patterns only\n",
    "    patterns = patterns[[3, 2, 4, 1, 5, 0, 6]]  # ordered by straightness\n",
    "    return patterns  # shape is (7, 8, 3)\n",
    "\n",
    "  def get_reshaped_patt_filters(self, patt_filters):\n",
    "    patt_filters = patt_filters[3]  # prompt patterns only\n",
    "    patt_filters = patt_filters[[3, 2, 4, 1, 5, 0, 6]]  # ordered by straightness\n",
    "    patt_filters = np.transpose(patt_filters, [3, 2, 1, 0])  # kernel shape is HWCD\n",
    "    return patt_filters  # shape is (1, 111, 8, 7)\n",
    "\n",
    "  def get_reshaped_patt_brightness(self, patt_brightness):\n",
    "    patt_brightness = patt_brightness // 4  # from 8-bit to 6-bit\n",
    "    assert patt_brightness.max() == 63\n",
    "    return patt_brightness  # shape is (256,)\n",
    "\n",
    "\n",
    "def load_patterns():\n",
    "  helper = PatternHelper()\n",
    "\n",
    "  patterns = []\n",
    "  patt_filters = []\n",
    "  patt_brightness = []\n",
    "  for z in range(num_emtf_zones):\n",
    "    fname = patterns_fname.replace('zone%i' % zone, 'zone%i' % z)  # modify filename\n",
    "    logger.info('Loading from {}'.format(fname))\n",
    "    with np.load(fname) as loaded:\n",
    "      patterns.append(helper.get_reshaped_patterns(loaded['patterns']))\n",
    "      patt_filters.append(helper.get_reshaped_patt_filters(loaded['boxes_act']))\n",
    "      patt_brightness.append(helper.get_reshaped_patt_brightness(loaded['hitmap_quality_ranks']))\n",
    "\n",
    "  patterns = np.asarray(patterns)\n",
    "  patt_filters = np.asarray(patt_filters)\n",
    "  patt_brightness = np.asarray(patt_brightness)\n",
    "  logger.info('patterns: {} patt_filters: {} patt_brightness: {}'.format(\n",
    "      patterns.shape, patt_filters.shape, patt_brightness.shape))\n",
    "  return (patterns, patt_filters, patt_brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading from patterns_zone0.npz\n",
      "[INFO    ] Loading from patterns_zone1.npz\n",
      "[INFO    ] Loading from patterns_zone2.npz\n",
      "[INFO    ] patterns: (3, 7, 8, 3) patt_filters: (3, 1, 111, 8, 7) patt_brightness: (3, 256)\n",
      "[INFO    ] Loading from signal_add.20210112.npz\n",
      "[INFO    ] out_part: (2000000, 9) out_hits: (2000000, None, 18) out_simhits: (2000000, None, 18)\n"
     ]
    }
   ],
   "source": [
    "# Load patterns\n",
    "patterns, patt_filters, patt_brightness = load_patterns()\n",
    "\n",
    "pattern_bank = emtf_nnet.keras.utils.PatternBank(\n",
    "    patterns=patterns, patt_filters=patt_filters, patt_brightness=patt_brightness)\n",
    "emtf_nnet.keras.utils.save_pattern_bank(pattern_bank)  # write to file\n",
    "\n",
    "# Load signal, bkgnd\n",
    "out_part, out_hits, out_simhits = load_signal()\n",
    "\n",
    "#out_bkg_aux, out_bkg_hits = load_bkgnd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "from emtf_nnet.architecture import endless_v3\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "#tf.config.threading.set_inter_op_parallelism_threads(32)\n",
    "#tf.config.threading.set_intra_op_parallelism_threads(32)\n",
    "\n",
    "loaded_pattern_bank = emtf_nnet.keras.utils.load_pattern_bank('pattern_bank.json')  #FIXME: currently hardcoded\n",
    "endless_v3.set_pattern_bank(loaded_pattern_bank)\n",
    "\n",
    "config = endless_v3.configure()\n",
    "endless_v3.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] out_part: (1804493, 9) out_hits: (1804493, None, 18) out_simhits: (1804493, None, 18)\n"
     ]
    }
   ],
   "source": [
    "# Create inputs\n",
    "def get_ragged_tensor(x):\n",
    "  return emtf_nnet.ragged.RaggedTensorValue(values=x[0], row_splits=x[1])\n",
    "\n",
    "zone_part, zone_hits, zone_simhits = endless_v3.create_zone_hits(out_part, out_hits, out_simhits)\n",
    "\n",
    "logger.info('out_part: {} out_hits: {} out_simhits: {}'.format(\n",
    "    zone_part.shape, get_ragged_tensor(zone_hits).shape, get_ragged_tensor(zone_simhits).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "datagen_sparse = endless_v3.get_datagen_sparse(zone_hits, batch_size=batch_size)\n",
    "try:\n",
    "  x_test_sparse = datagen_sparse[0]\n",
    "except:\n",
    "  raise ValueError('Fail to get data from datagen_sparse.')\n",
    "\n",
    "datagen = endless_v3.get_datagen(zone_hits, batch_size=batch_size)\n",
    "try:\n",
    "  x_test = datagen[0]\n",
    "except:\n",
    "  raise ValueError('Fail to get data from datagen.')\n",
    "\n",
    "assert isinstance(x_test_sparse, list) and len(x_test_sparse) == batch_size\n",
    "assert isinstance(x_test, np.ndarray) and len(x_test) == batch_size and x_test.ndim == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2,    0,  2548,    5,   18,   17,    6,    6,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  19,    0,  2684,    2,   16,   16,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  28,    0,  2819,   15,   17,   16,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  28,    1,  2728,    0,   16,   17,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  37,    0,  2736,    0,   16,   16,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  55,    0,  2505,    0,   18,   18,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  73,    0,  2675,    0,   19,   19,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  82,    0,  2888,    0,   17,   17,    1,    1,    1,    4,    4,    0,    0,    0,    1],\n",
      " [  82,    1,  2714,    0,   17,   17,    5,    5,    1,    4,    4,    0,    0,    0,    1],\n",
      " [  91,    0,  2737,    0,   17,   17,    1,    1,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 109,    0,  2479,   15,   17,   17,    6,    6,    0,    4,    4,    1,    0,    0,    1]]\n",
      "[[  29,    0,  4503,    1,   11,   11,    5,    5,    0,    4,    6,    1,    0,   -1,    1],\n",
      " [  11,    0,  4643,    0,   12,   12,    4,    4,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  20,    0,  4528,    0,   11,   11,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  38,    0,  4485,   -2,   11,   11,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  74,    0,  4547,    0,   12,   12,    2,    2,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  83,    0,  4483,    0,   10,   10,    4,    4,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  92,    0,  4483,    0,   11,   11,    2,    2,    1,    4,    4,    1,    0,    0,    1],\n",
      " [ 113,    0,  4661,   -6,   13,   13,    6,    6,    0,    4,    4,    1,    0,    0,    1]]\n",
      "[[   9,    0,  3420,   15,   17,   17,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [   9,    1,  3365,  -10,   17,   17,    5,    5,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  19,    0,  2992,   -3,   15,   15,    4,    4,    0,    4,    4,    0,    0,    0,    1],\n",
      " [  28,    0,  2943,    1,   14,   14,    5,    5,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  37,    0,  2956,    2,   14,   14,    5,    5,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  63,    0,  3401,    0,   18,   18,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  82,    0,  2938,    0,   15,   15,    3,    3,   -1,    4,    4,    1,    0,    0,    1],\n",
      " [  91,    0,  2975,    0,   14,   14,    1,    1,   -1,    4,    4,    1,    0,    0,    1],\n",
      " [ 111,    0,  3445,  -28,   18,   18,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [  37,    0,  2956,    2,   14,   14,    5,    5,    0,    4,    0,    1,    0,    1,    1]]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "my_array2string = functools.partial(\n",
    "    np.array2string, separator=', ', formatter={'int':lambda x: '% 4i' % x},\n",
    "    max_line_width=100, threshold=1000)\n",
    "\n",
    "print(my_array2string(x_test_sparse[0]))\n",
    "print(my_array2string(x_test_sparse[2]))\n",
    "print(my_array2string(x_test_sparse[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 115, 2, 13)\n",
      "[[ 2548,    5,   18,   17,    6,    6,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2684,    2,   16,   16,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2819,   15,   17,   16,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2728,    0,   16,   17,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2736,    0,   16,   16,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2505,    0,   18,   18,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2675,    0,   19,   19,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2888,    0,   17,   17,    1,    1,    1,    4,    4,    0,    0,    0,    1],\n",
      " [ 2714,    0,   17,   17,    5,    5,    1,    4,    4,    0,    0,    0,    1],\n",
      " [ 2737,    0,   17,   17,    1,    1,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2479,   15,   17,   17,    6,    6,    0,    4,    4,    1,    0,    0,    1]]\n",
      "[[ 4643,    0,   12,   12,    4,    4,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 4528,    0,   11,   11,    5,    5,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 4503,    1,   11,   11,    5,    5,    0,    4,    6,    1,    0,   -1,    1],\n",
      " [ 4485,   -2,   11,   11,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 4547,    0,   12,   12,    2,    2,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 4483,    0,   10,   10,    4,    4,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 4483,    0,   11,   11,    2,    2,    1,    4,    4,    1,    0,    0,    1],\n",
      " [ 4661,   -6,   13,   13,    6,    6,    0,    4,    4,    1,    0,    0,    1]]\n",
      "[[ 3420,   15,   17,   17,    6,    6,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 3365,  -10,   17,   17,    5,    5,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2992,   -3,   15,   15,    4,    4,    0,    4,    4,    0,    0,    0,    1],\n",
      " [ 2943,    1,   14,   14,    5,    5,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2956,    2,   14,   14,    5,    5,    0,    4,    0,    1,    0,    1,    1],\n",
      " [ 3401,    0,   18,   18,    2,    2,    0,    4,    4,    1,    0,    0,    1],\n",
      " [ 2938,    0,   15,   15,    3,    3,   -1,    4,    4,    1,    0,    0,    1],\n",
      " [ 2975,    0,   14,   14,    1,    1,   -1,    4,    4,    1,    0,    0,    1],\n",
      " [ 3445,  -28,   18,   18,    6,    6,    0,    4,    4,    1,    0,    0,    1]]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "isvalid = lambda x: (x[..., -1] != 0)  # x[..., -1] is the valid flag\n",
    "\n",
    "print(x_test.shape)\n",
    "print(my_array2string(x_test[0][isvalid(x_test[0])]))\n",
    "print(my_array2string(x_test[2][isvalid(x_test[2])]))\n",
    "print(my_array2string(x_test[13][isvalid(x_test[13])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting ScatterNd\n",
      "Model: \"endless_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 115, 2, 13)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zoning_0 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_1 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_2 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pooling_0 (Pooling)             ((None, 288), (None, 6272        zoning_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_1 (Pooling)             ((None, 288), (None, 6272        zoning_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_2 (Pooling)             ((None, 288), (None, 6272        zoning_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "suppression_0 (Suppression)     ((None, 288), (None, 0           pooling_0[0][0]                  \n",
      "                                                                 pooling_0[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "suppression_1 (Suppression)     ((None, 288), (None, 0           pooling_1[0][0]                  \n",
      "                                                                 pooling_1[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "suppression_2 (Suppression)     ((None, 288), (None, 0           pooling_2[0][0]                  \n",
      "                                                                 pooling_2[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_0 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_0[0][0]              \n",
      "                                                                 suppression_0[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_1 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_1[0][0]              \n",
      "                                                                 suppression_1[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "zonesorting_2 (ZoneSorting)     ((None, 4), (None, 4 0           suppression_2[0][0]              \n",
      "                                                                 suppression_2[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_0 (Concatenate)     (None, 12)           0           zonesorting_0[0][0]              \n",
      "                                                                 zonesorting_1[0][0]              \n",
      "                                                                 zonesorting_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12)           0           zonesorting_0[0][1]              \n",
      "                                                                 zonesorting_1[0][1]              \n",
      "                                                                 zonesorting_2[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12)           0           zonesorting_0[0][2]              \n",
      "                                                                 zonesorting_1[0][2]              \n",
      "                                                                 zonesorting_2[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "zonemerging_0 (ZoneMerging)     ((None, 4), (None, 4 0           concatenate_0[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "trkbuilding_0 (TrkBuilding)     ((None, 4, 40), (Non 0           inputs[0][0]                     \n",
      "                                                                 zonemerging_0[0][0]              \n",
      "                                                                 zonemerging_0[0][1]              \n",
      "                                                                 zonemerging_0[0][2]              \n",
      "                                                                 zonemerging_0[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "duperemoval_0 (DupeRemoval)     ((None, 4, 40), (Non 0           trkbuilding_0[0][0]              \n",
      "                                                                 trkbuilding_0[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "trainfilter_0 (TrainFilter)     ((None, 4, 40), (Non 0           duperemoval_0[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 18,816\n",
      "Trainable params: 0\n",
      "Non-trainable params: 18,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = endless_v3.create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterMax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] outputs: (1024, 4, 40) dtype: int32\n",
      "[INFO    ] outputs: (1024, 4, 12) dtype: int32\n",
      "[INFO    ] outputs: (1024, 4, 1) dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "outputs = model.predict(x_test, workers=workers, use_multiprocessing=False)  # now wait...\n",
    "if isinstance(outputs, tuple):\n",
    "  for i in range(len(outputs)):\n",
    "    logger.info('outputs: {} dtype: {}'.format(outputs[i].shape, outputs[i].dtype))\n",
    "else:\n",
    "  logger.info('outputs: {} dtype: {}'.format(outputs.shape, outputs.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[  -116, 999999,     20, ...,     16,     63,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]],\n",
      "\n",
      "       [[  -251, 999999,     -3, ...,      7,     61,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]],\n",
      "\n",
      "       [[   123, 999999,      8, ...,     11,     63,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[999999, 999999,     20, ...,     87,     34,      0],\n",
      "        [999999, 999999, 999999, ...,      0,      0,      0],\n",
      "        [999999, 999999, 999999, ...,      0,      0,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]],\n",
      "\n",
      "       [[999999,    -25,     20, ...,     77,     63,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]],\n",
      "\n",
      "       [[999999,    110,     16, ...,     67,     63,      0],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999],\n",
      "        [999999, 999999, 999999, ..., 999999, 999999, 999999]]],\n",
      "      dtype=int32), array([[[  4, 230,  30, ..., 168, 182, 190],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]],\n",
      "\n",
      "       [[  0, 230,  28, ..., 230, 180, 188],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]],\n",
      "\n",
      "       [[ 10, 230,  32, ..., 230, 184, 198],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[230, 230,  44, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]],\n",
      "\n",
      "       [[230,  20,  42, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]],\n",
      "\n",
      "       [[230,  22,  44, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230],\n",
      "        [230, 230, 230, ..., 230, 230, 230]]], dtype=int32), array([[[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]],\n",
      "\n",
      "       [[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]],\n",
      "\n",
      "       [[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]],\n",
      "\n",
      "       [[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]],\n",
      "\n",
      "       [[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False]]]))\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -116 999999     20     64     72 999999 999999     50     73   -159\n",
      "     11   -185      1 999999      0      0      0 999999 999999      1\n",
      "      1      2      3      1      5 999999      2      0      0     15\n",
      "      6 999999      6      5      5      6    -80     16     63      0]\n",
      "[  4 230  30  53  74 230 230 125 146 168 182 190]\n",
      "[   123 999999      8    -17    -35 999999 999999    -37    -37 999999\n",
      "     27    141      1 999999      0      0      0 999999 999999     -1\n",
      "      0 999999      1      2      0 999999      0      1     -2     -6\n",
      "      4 999999      5      5      6      6   1776     11     63      0]\n",
      "[ 10 230  32  54  76 230 230 126 148 230 184 198]\n",
      "[   381 999999      8    -41 999999 999999 999999    -46     -9    417\n",
      " 999999    461      3 999999      1      0 999999 999999 999999      1\n",
      "      0      4 999999      4    -10 999999     -3      1 999999    -28\n",
      "      5 999999      4      5 999999      6    240     14     63      0]\n",
      "[  7 230  30  52 230 230 230 124 146 172 230 194]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(outputs[0][0, 0])\n",
    "print(outputs[1][0, 0])\n",
    "print(outputs[0][2, 0])\n",
    "print(outputs[1][2, 0])\n",
    "print(outputs[0][13, 0])\n",
    "print(outputs[1][13, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1e+03 ns, total: 11 µs\n",
      "Wall time: 31 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if maxevents == -1:\n",
    "  outputs = model.predict(datagen, workers=workers, use_multiprocessing=False)  # now wait...\n",
    "  if isinstance(outputs, tuple):\n",
    "    for i in range(len(outputs)):\n",
    "      logger.info('outputs: {} dtype: {}'.format(outputs[i].shape, outputs[i].dtype))\n",
    "  else:\n",
    "    logger.info('outputs: {} dtype: {}'.format(outputs.shape, outputs.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and truths for training\n",
    "if maxevents == -1:\n",
    "  features = outputs[0][:, 0, :]\n",
    "  truths = zone_part\n",
    "  passed = outputs[2][:, 0, 0]\n",
    "\n",
    "  features, truths = (x[passed] for x in (features, truths))\n",
    "  logger.info('features: {0} dtype: {1}'.format(features.shape, features.dtype))\n",
    "  logger.info('truths: {0} dtype: {1}'.format(truths.shape, truths.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features and truths\n",
    "if maxevents == -1:\n",
    "  def doit():\n",
    "    fig, axs = plt.subplots(ni, nj, figsize=(6,6*ni/nj))\n",
    "    for i in range(ni):\n",
    "      for j in range(nj):\n",
    "        ij = (i * nj) + j\n",
    "        if ij >= nij:\n",
    "          break\n",
    "        #\n",
    "        if axs.ndim == 2:\n",
    "          ax = axs[i, j]\n",
    "        elif axs.ndim == 1:\n",
    "          ax = axs[j]\n",
    "        else:\n",
    "          ax = axs\n",
    "        ax.hist(axdata[:, ij])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "  ni, nj = 7, 6\n",
    "  nij = features.shape[1]\n",
    "  axdata = features\n",
    "  doit()\n",
    "\n",
    "  ni, nj = 2, 6\n",
    "  nij = truths.shape[1]\n",
    "  axdata = truths\n",
    "  doit()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "if maxevents == -1:\n",
    "  outfile = 'features.h5'\n",
    "  outdict = {'features': da.from_array(features), 'truths': da.from_array(truths)}\n",
    "  da.to_hdf5(outfile, outdict, compression='lzf')\n",
    "  logger.info('Wrote to {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
