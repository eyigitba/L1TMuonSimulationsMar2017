{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "  print('[ERROR] You need to run this with Python 3.')\n",
    "  raise AssertionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from emtf_algos import *\n",
    "from emtf_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw      : CMSSW_10_6_3\n",
      "[INFO    ] Using python     : 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) [GCC 7.3.0]\n",
      "[INFO    ] Using numpy      : 1.19.1\n",
      "[INFO    ] Using tensorflow : 2.2.0\n",
      "[INFO    ] Using keras      : 2.3.0-tf\n",
      "[INFO    ] .. list devices  : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')]\n",
      "[INFO    ] Using matplotlib : 3.2.2\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(2027)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers as k_layers\n",
    "from tensorflow.keras import backend as k_backend\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(2027)\n",
    "\n",
    "#import numba\n",
    "#from numba import njit, vectorize\n",
    "#import dask\n",
    "#import dask.array as da\n",
    "\n",
    "logger = get_logger()\n",
    "logger.info('Using cmssw      : {0}'.format(os.environ['CMSSW_VERSION'] if 'CMSSW_VERSION' in os.environ else 'n/a'))\n",
    "logger.info('Using python     : {0}'.format(sys.version.replace('\\n', '')))\n",
    "logger.info('Using numpy      : {0}'.format(np.__version__))\n",
    "logger.info('Using tensorflow : {0}'.format(tf.__version__))\n",
    "logger.info('Using keras      : {0}'.format(keras.__version__))\n",
    "logger.info('.. list devices  : {0}'.format(tf.config.list_physical_devices()))\n",
    "logger.info('Using matplotlib : {0}'.format(mpl.__version__))\n",
    "#logger.info('Using numba      : {0}'.format(numba.__version__))\n",
    "#logger.info('Using dask       : {0}'.format(dask.__version__))\n",
    "\n",
    "assert k_backend.backend() == 'tensorflow'\n",
    "assert k_backend.image_data_format() == 'channels_last'\n",
    "assert int(tf.version.VERSION.split('.')[0]) >= 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Processing zone 0 timezone 1\n",
      "[INFO    ] .. maxevents        : 10\n",
      "[INFO    ] .. image_format     : (8, 288, 1)\n",
      "[INFO    ] .. image_stride     : (432, 5040, 16)\n",
      "[INFO    ] .. box_image_format : (8, 111, 1)\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# zone: (0,1,2) -> eta=(1.98..2.5, 1.55..1.98, 1.2..1.55)\n",
    "zone = 0\n",
    "#zone = 1\n",
    "#zone = 2\n",
    "\n",
    "# timezone: (0,1,2) -> BX=(-1,0,+1)\n",
    "timezone = 1\n",
    "\n",
    "maxevents = 10\n",
    "#maxevents = -1\n",
    "\n",
    "# Input files\n",
    "patterns_fname = 'patterns_zone%i.npz' % zone\n",
    "zone_images_fname = 'zone_images_zone%i.h5' % zone\n",
    "\n",
    "# Input data columns\n",
    "part_metadata = ['part_invpt', 'part_eta', 'part_phi',\n",
    "                 'part_vx', 'part_vy', 'part_vz',\n",
    "                 'part_d0', 'part_sector', 'part_zone']\n",
    "part_metadata = dict(zip(part_metadata, range(len(part_metadata))))\n",
    "#print(part_metadata)\n",
    "\n",
    "hits_metadata = ['emtf_layer', 'ri_layer', 'zones', 'timezones',\n",
    "                 'emtf_chamber', 'emtf_segment', 'detlayer', 'bx',\n",
    "                 'emtf_phi', 'emtf_bend', 'emtf_theta', 'emtf_theta_alt',\n",
    "                 'emtf_qual', 'emtf_time', 'fr', 'rsvd']\n",
    "hits_metadata = dict(zip(hits_metadata, range(len(hits_metadata))))\n",
    "#print(hits_metadata)\n",
    "\n",
    "# Info regarding phi unit\n",
    "# 80 deg is converted to (80.*60)/16 = 300 units.\n",
    "# 30 deg is converted to (30.*60)/16 = 112.5 units.\n",
    "# 300 units aligned to 16-bit is np.floor(300./16)*16 = 288 units.\n",
    "# 112.5 units aligned to 16-bit is np.floor(112.5/16) * 16 = 112 units,\n",
    "# 112 is then lowered to the closest odd number 111.\n",
    "\n",
    "# Image format\n",
    "num_channels = 1\n",
    "num_cols = 288  # 80 degrees\n",
    "num_rows = 8\n",
    "image_format = (num_rows, num_cols, num_channels)\n",
    "\n",
    "# Image sliding window\n",
    "image_stride = (min_emtf_strip, max_emtf_strip, coarse_emtf_strip)\n",
    "assert ((max_emtf_strip - min_emtf_strip) // coarse_emtf_strip) == num_cols\n",
    "\n",
    "# Box image format\n",
    "num_box_rows = num_rows\n",
    "num_box_cols = 111  # 30 degrees\n",
    "num_box_channels = num_channels\n",
    "box_image_format = (num_box_rows, num_box_cols, num_box_channels)\n",
    "box_col_offset = (num_box_cols-1)//2  # (111-1)/2 = 55\n",
    "assert (num_box_cols % 2) == 1\n",
    "\n",
    "logger.info('Processing zone {0} timezone {1}'.format(zone, timezone))\n",
    "logger.info('.. maxevents        : {0}'.format(maxevents))\n",
    "logger.info('.. image_format     : {0}'.format(image_format))\n",
    "logger.info('.. image_stride     : {0}'.format(image_stride))\n",
    "logger.info('.. box_image_format : {0}'.format(box_image_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "plt.style.use('tdrstyle.mplstyle')\n",
    "\n",
    "# Color maps\n",
    "from matplotlib.colors import ListedColormap\n",
    "my_cmap = ListedColormap(plt.cm.viridis.colors, name='viridis_mod')\n",
    "my_cmap.set_under('w',1)\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cdict = {\n",
    "  'blue' : ((0.0, 0.0416, 0.0416), (0.365079, 1.0, 1.0), (1.0, 1.0, 1.0)),\n",
    "  'green': ((0.0, 0.0, 0.0), (0.365079, 0.0, 0.0), (0.746032, 1.0, 1.0), (1.0, 1.0, 1.0)),\n",
    "  'red'  : ((0.0, 0.0, 0.0), (0.746032, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "}\n",
    "blue_hot = LinearSegmentedColormap('blue_hot', cdict)\n",
    "\n",
    "cdict = {\n",
    "  'blue' : ((0.0, 0.0, 0.0), (0.365079, 0.0, 0.0), (0.746032, 1.0, 1.0), (1.0, 1.0, 1.0)),\n",
    "  'green': ((0.0, 0.0416, 0.0416), (0.365079, 1.0, 1.0), (1.0, 1.0, 1.0)),\n",
    "  'red'  : ((0.0, 0.0, 0.0), (0.746032, 0.0, 0.0), (1.0, 1.0, 1.0)),\n",
    "}\n",
    "green_hot = LinearSegmentedColormap('green_hot', cdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patterns():\n",
    "  patterns = []\n",
    "  boxes_act = []\n",
    "  for i in range(num_emtf_zones):\n",
    "    fname = patterns_fname.replace('zone%i' % zone, 'zone%i' % i)\n",
    "    logger.info('Loading from {0}'.format(fname))\n",
    "    with np.load(fname) as loaded:\n",
    "      patterns.append(loaded['patterns'])\n",
    "      boxes_act.append(loaded['boxes_act'])\n",
    "  patterns = np.asarray(patterns)\n",
    "  boxes_act = np.asarray(boxes_act)\n",
    "  logger.info('patterns: {0} boxes_act: {1}'.format(patterns.shape, boxes_act.shape))\n",
    "  return (patterns, boxes_act)\n",
    "\n",
    "import h5py\n",
    "loaded_h5 = None  # hdf5 file handle\n",
    "\n",
    "def load_zone_sparse_images(fname):\n",
    "  global loaded_h5\n",
    "  if loaded_h5 is None:\n",
    "    logger.info('Loading from {0}'.format(fname))\n",
    "    loaded_h5 = h5py.File(fname, 'r')\n",
    "  zone_box_anchors = loaded_h5['zone_box_anchors']\n",
    "  zone_sparse_images = SparseTensorValue(indices=loaded_h5['zone_sparse_images_indices'],\n",
    "                                         values=loaded_h5['zone_sparse_images_values'],\n",
    "                                         dense_shape=loaded_h5['zone_sparse_images_dense_shape'])\n",
    "  logger.info('zone_box_anchors: {0} zone_sparse_images: {1}'.format(zone_box_anchors.shape, zone_sparse_images.dense_shape))\n",
    "  return zone_box_anchors, zone_sparse_images\n",
    "\n",
    "def load_zone_hits(fname):\n",
    "  global loaded_h5\n",
    "  if loaded_h5 is None:\n",
    "    logger.info('Loading from {0}'.format(fname))\n",
    "    loaded_h5 = h5py.File(fname, 'r')\n",
    "  zone_part = loaded_h5['zone_part']\n",
    "  zone_hits = RaggedTensorValue(values=loaded_h5['zone_hits_values'],\n",
    "                                row_splits=loaded_h5['zone_hits_row_splits'])\n",
    "  zone_simhits = RaggedTensorValue(values=loaded_h5['zone_simhits_values'],\n",
    "                                   row_splits=loaded_h5['zone_simhits_row_splits'])\n",
    "  logger.info('zone_part: {0} zone_hits: {1} zone_simhits: {2}'.format(zone_part.shape, zone_hits.shape, zone_simhits.shape))\n",
    "  return zone_part, zone_hits, zone_simhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading from patterns_zone0.npz\n",
      "[INFO    ] Loading from patterns_zone1.npz\n",
      "[INFO    ] Loading from patterns_zone2.npz\n",
      "[INFO    ] patterns: (3, 7, 7, 8, 3) boxes_act: (3, 7, 7, 8, 111, 1)\n",
      "[INFO    ] boxes_act_test: (3, 1, 111, 8, 7)\n"
     ]
    }
   ],
   "source": [
    "patterns, boxes_act = load_patterns()\n",
    "\n",
    "boxes_act_test = boxes_act[:, 3]  # use only the prompt muon row\n",
    "boxes_act_test = np.transpose(boxes_act_test, [0, 4, 3, 2, 1])\n",
    "logger.info('boxes_act_test: {0}'.format(boxes_act_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading from zone_images_zone0.h5\n",
      "[INFO    ] zone_part: (761923, 9) zone_hits: (761923, None, 16) zone_simhits: (761923, None, 16)\n"
     ]
    }
   ],
   "source": [
    "zone_part, zone_hits, zone_simhits = load_zone_hits(zone_images_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patterns = 7\n",
    "num_tracks = 4\n",
    "num_track_variables = 36\n",
    "\n",
    "num_embedding_input_dim = 2 ** 11\n",
    "num_embedding_input_bw = 11\n",
    "\n",
    "ind_emtf_phi = hits_metadata['emtf_phi']\n",
    "ind_emtf_bend = hits_metadata['emtf_bend']\n",
    "ind_emtf_theta = hits_metadata['emtf_theta']\n",
    "ind_emtf_theta_alt = hits_metadata['emtf_theta_alt']\n",
    "ind_emtf_qual = hits_metadata['emtf_qual']\n",
    "ind_emtf_time = hits_metadata['emtf_time']\n",
    "ind_bx = hits_metadata['bx']\n",
    "ind_valid = hits_metadata['rsvd']  # CUIDADO: use 'rsvd' for the moment\n",
    "\n",
    "ind_emtf_chamber = hits_metadata['emtf_chamber']\n",
    "ind_emtf_segment = hits_metadata['emtf_segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs():\n",
    "  inputs = []\n",
    "  for ievt in range(zone_hits.shape[0]):\n",
    "    if maxevents != -1 and ievt == maxevents:\n",
    "      break\n",
    "\n",
    "    dense_shape = np.array([num_emtf_chambers, num_emtf_segments, num_emtf_variables], dtype=np.int32)\n",
    "    indices = zone_hits[ievt][:, [ind_emtf_chamber, ind_emtf_segment]]\n",
    "    values = zone_hits[ievt][:, [ind_emtf_phi, ind_emtf_bend, ind_emtf_theta, ind_emtf_theta_alt, ind_emtf_qual, ind_emtf_time, ind_bx, ind_valid]]\n",
    "    values[:, -1] = 1  # CUIDADO: set valid to 1\n",
    "    #print(dense_shape)\n",
    "    #print(indices.shape, indices)\n",
    "    #print(values.shape, values)\n",
    "\n",
    "    # Apply truncation\n",
    "    valid = indices[:, 1] < num_emtf_segments\n",
    "    indices = indices[valid]\n",
    "    values = values[valid]\n",
    "\n",
    "    # Mimic sparse_to_dense()\n",
    "    ndims = indices.shape[1]\n",
    "    tup = tuple(indices[: ,i] for i in range(ndims))\n",
    "    dense = np.zeros(dense_shape, dtype=values.dtype)\n",
    "    dense[tup] = values\n",
    "    inputs.append(dense)\n",
    "  return np.asarray(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] inputs: (10, 115, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "inputs = create_inputs()\n",
    "\n",
    "logger.info('inputs: {0}'.format(inputs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zone_images(x, zone=zone, image_format=image_format):\n",
    "  # Utility functions & LUTs\n",
    "  inverse_fn = lambda F, y: [[i for (i, y_i) in enumerate(F) if y_i == y_j] for y_j in y]\n",
    "  to_array = lambda x: np.asarray([np.asarray(x_i) for x_i in x])\n",
    "  to_list = lambda x: [x_i.tolist() for x_i in x]\n",
    "  flatten = lambda x: np.asarray([x_i_i for x_i in x for x_i_i in x_i])\n",
    "\n",
    "  def to_array(x):  # improved version\n",
    "    ragged = len(set([len(x_i) for x_i in x])) > 1\n",
    "    if ragged:\n",
    "      return np.asarray([np.asarray(x_i) for x_i in x], dtype=np.object)\n",
    "    return np.asarray([x_i for x_i in x])\n",
    "\n",
    "  num_emtf_ri_layers = 19\n",
    "  ri_layer_to_chamber_lut = to_array(inverse_fn(chamber_to_ri_layer_lut, range(num_emtf_ri_layers)))\n",
    "  #ri_layer_to_chamber_lut_flat = flatten(ri_layer_to_chamber_lut)\n",
    "\n",
    "  num_emtf_zo_layers = 8\n",
    "  ri_layer_to_zo_layer_lut = find_emtf_zo_layer_lut()[:, zone]\n",
    "  zo_layer_to_ri_layer_lut = to_array(inverse_fn(ri_layer_to_zo_layer_lut, range(num_emtf_zo_layers)))\n",
    "\n",
    "  ri_layer_to_zo_bounds_lut_0 = find_emtf_zones_lut()[:, zone, 0]\n",
    "  ri_layer_to_zo_bounds_lut_1 = find_emtf_zones_lut()[:, zone, 1]\n",
    "  zo_layer_to_chamber_lut = to_array([\n",
    "      [c for ri_layer in ri_layers for c in ri_layer_to_chamber_lut[ri_layer]] \\\n",
    "      for ri_layers in zo_layer_to_ri_layer_lut\n",
    "  ])\n",
    "  zo_layer_to_zo_bounds_lut_0 = to_array([\n",
    "      [ri_layer_to_zo_bounds_lut_0[ri_layer] for ri_layer in ri_layers for c in ri_layer_to_chamber_lut[ri_layer]] \\\n",
    "      for ri_layers in zo_layer_to_ri_layer_lut\n",
    "  ])\n",
    "  zo_layer_to_zo_bounds_lut_1 = to_array([\n",
    "      [ri_layer_to_zo_bounds_lut_1[ri_layer] for ri_layer in ri_layers for c in ri_layer_to_chamber_lut[ri_layer]] \\\n",
    "      for ri_layers in zo_layer_to_ri_layer_lut\n",
    "  ])\n",
    "\n",
    "  def get_boolean_mask(zo_layer):\n",
    "    indices = zo_layer_to_chamber_lut[zo_layer]\n",
    "    boolean_mask = np.zeros(num_emtf_chambers, dtype=np.bool)\n",
    "    boolean_mask[indices] = 1\n",
    "    return boolean_mask\n",
    "\n",
    "  def get_bounds_low(zo_layer):\n",
    "    return zo_layer_to_zo_bounds_lut_0[zo_layer][:, np.newaxis]\n",
    "\n",
    "  def get_bounds_hi(zo_layer):\n",
    "    return zo_layer_to_zo_bounds_lut_1[zo_layer][:, np.newaxis]\n",
    "\n",
    "  # Prepare zone images\n",
    "  zone_images = np.zeros((x.shape[0],) + image_format, dtype=np.bool)\n",
    "\n",
    "  for ievt in range(zone_images.shape[0]):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    channels = []\n",
    "    for zo_layer in range(zone_images.shape[1]):\n",
    "      boolean_mask = get_boolean_mask(zo_layer)\n",
    "      bounds_low = get_bounds_low(zo_layer)\n",
    "      bounds_hi = get_bounds_hi(zo_layer)\n",
    "\n",
    "      x_emtf_phi = x[ievt][boolean_mask][..., 0]\n",
    "      x_emtf_theta = x[ievt][boolean_mask][..., 2]\n",
    "      x_emtf_theta_alt = x[ievt][boolean_mask][..., 3]\n",
    "      x_valid = x[ievt][boolean_mask][..., 7]\n",
    "\n",
    "      valid = (x_valid == 1) & \\\n",
    "              (((bounds_low <= x_emtf_theta) & (x_emtf_theta <= bounds_hi)) | \\\n",
    "               ((bounds_low <= x_emtf_theta_alt) & (x_emtf_theta_alt <= bounds_hi)))\n",
    "      col = find_emtf_zo_phi(x_emtf_phi[valid])\n",
    "\n",
    "      rows.extend([zo_layer for _ in col])\n",
    "      cols.extend(col)\n",
    "      channels.extend([0 for _ in col])\n",
    "\n",
    "    # Fill zone image\n",
    "    zone_images[ievt][(rows, cols, channels)] = 1\n",
    "  return zone_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = np.zeros((num_emtf_zones, num_embedding_input_dim), dtype=np.int32)\n",
    "\n",
    "straightness = np.array([0, 1, 1, 2, 1, 1, 0, 0], dtype=np.int32)\n",
    "\n",
    "priority = [\n",
    "  [-1, 0, 1, 4, 5, 5, 7, 6, 3, 3, 2],  # zone 0\n",
    "  [-1, 0, 1, 4, 5, 5, 7, 6, 3, 2, 2],  # zone 1\n",
    "  [-1, 0, 1, 4, 4, 5, 5, 7, 6, 3, 2],  # zone 2\n",
    "]\n",
    "priority = np.asarray(priority, dtype=np.int32)\n",
    "\n",
    "# Loop over zone\n",
    "for i in range(num_emtf_zones):\n",
    "  # Loop over embedding input dim\n",
    "  for j in range(num_embedding_input_dim):\n",
    "    # Loop over priority codes\n",
    "    for k in range(num_embedding_input_bw):\n",
    "      jj = ((j >> 3) << 3) | straightness[(j & 0x7)]  # set last 3 bits to straightness\n",
    "      kk = priority[i][k]  # read priority code\n",
    "      if (kk != -1) and (jj & (1 << k)):  # test bit\n",
    "        embedding_weights[i, j] |= (1 << kk)  # set embedding output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom layers\n",
    "# See: https://www.tensorflow.org/tutorials/customization/custom_layers\n",
    "\n",
    "class Zoning(k_layers.Layer):\n",
    "  def __init__(self, zone, image_format=image_format, **kwargs):\n",
    "    super(Zoning, self).__init__(**kwargs)\n",
    "    self.zone = zone\n",
    "    self.image_format = image_format\n",
    "\n",
    "    # Call build_zone_images()\n",
    "    import functools\n",
    "    kwargs = dict(zone=self.zone, image_format=self.image_format)\n",
    "    _build_zone_images = functools.partial(build_zone_images, **kwargs)\n",
    "    #py_func = lambda x: tf.py_function(_build_zone_images, [x], tf.bool)\n",
    "    py_func = lambda x: tf.numpy_function(_build_zone_images, [x], tf.bool)\n",
    "    self.py_func = k_layers.Lambda(py_func)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = tf.cast(inputs, dtype=tf.int32)\n",
    "    x = self.py_func(x)\n",
    "    x = tf.cast(x, dtype=inputs.dtype)\n",
    "    output_shape = (None,) + self.image_format\n",
    "    x.set_shape(output_shape)\n",
    "    return x\n",
    "\n",
    "class Pooling(k_layers.Layer):\n",
    "  def __init__(self, zone, image_format=image_format, num_box_cols=num_box_cols,\n",
    "               num_patterns=num_patterns, **kwargs):\n",
    "    super(Pooling, self).__init__(**kwargs)\n",
    "    self.zone = zone\n",
    "    self.image_format = image_format\n",
    "    self.num_box_cols = num_box_cols\n",
    "    self.num_patterns = num_patterns\n",
    "\n",
    "    # SeparableConv2D but only the depthwise conv (i.e. without the pointwise conv)\n",
    "    # See: https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D\n",
    "    # See: https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D\n",
    "    from k_layers_separable_conv2d import SeparableConv2D as MySeparableConv2D\n",
    "    w_init = tf.keras.initializers.Constant(boxes_act_test[self.zone])\n",
    "    conv2d_kwargs = dict(filters=1, kernel_size=(1, self.num_box_cols), depth_multiplier=self.num_patterns,\n",
    "                         strides=(1, 1), padding='same', activation=None, use_bias=False,\n",
    "                         depthwise_initializer=w_init, pointwise_initializer='ones', trainable=False)\n",
    "    self.conv2d = MySeparableConv2D(**conv2d_kwargs)\n",
    "\n",
    "    # Dot product coeffs for packing the last axis\n",
    "    self.w = np.arange(self.image_format[0])[::-1]  # (7, 6, 5, 4, 3, 2, 1)\n",
    "    self.w = 2 ** (self.w + 3)  # do power of 2, with 3 additional bits\n",
    "    self.b = np.arange(self.num_patterns)  # (0, 1, 2, 3, 4, 5, 6)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Conv\n",
    "    x = inputs\n",
    "    x = tf.transpose(x, perm=(0, 3, 2, 1))  # NHWC -> NCWH\n",
    "    x = self.conv2d(x)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    x = tf.reshape(x, [-1, self.image_format[2], self.image_format[1], self.image_format[0], self.num_patterns])  # NCWHX\n",
    "    x = tf.transpose(x, perm=(0, 1, 2, 4, 3))  # NCWHX -> NCWXH\n",
    "\n",
    "    # Pack the last axis\n",
    "    x = tf.reduce_sum(x * self.w, axis=-1)  # pack the 8 bits from H into a single number, w is power of 2 series\n",
    "    x = x + self.b  # additional 3 bits for pattern number, b is pattern number\n",
    "    x = tf.reduce_sum(x, axis=1)  # NCWX -> NWX, C is dim of size 1\n",
    "    return x\n",
    "\n",
    "class Erosion(k_layers.Layer):\n",
    "  def __init__(self, zone, image_format=image_format,\n",
    "               **kwargs):\n",
    "    super(Erosion, self).__init__(**kwargs)\n",
    "    self.zone = zone\n",
    "    self.image_format = image_format\n",
    "\n",
    "    # Embedding\n",
    "    # See: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "    w_init = tf.keras.initializers.Constant(embedding_weights[self.zone])  #FIXME: add thresholds?\n",
    "    embedding_kwargs = dict(input_dim=num_embedding_input_dim, output_dim=1, input_length=1,\n",
    "                            embeddings_initializer=w_init, trainable=False)\n",
    "    self.embedding = k_layers.Embedding(**embedding_kwargs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Embedding\n",
    "    x = inputs\n",
    "    x = self.embedding(x)\n",
    "    x = tf.reduce_sum(x, axis=-1)  # NWXY -> NWX, Y is dim of size 1\n",
    "    x = tf.floor(x / 4)  # truncate the last two bits\n",
    "\n",
    "    # Non max suppression\n",
    "    # Regarding the usage of tf.gather_nd(), see https://stackoverflow.com/q/50578544\n",
    "    indices = tf.argmax(x, axis=-1, output_type=tf.int32)\n",
    "    indices_0 = tf.meshgrid(tf.range(tf.shape(indices)[0]), tf.range(indices.shape[1]), indexing='ij')\n",
    "    indices = tf.stack(indices_0 + [indices], axis=-1)\n",
    "    x = tf.gather_nd(x, indices)  # like x = x[indices]\n",
    "    #x_padded = tf.pad(x, paddings=[[0, 0], [1, 1]])  # note: x == x_padded[:, 1:-1]\n",
    "    #mask = (x > x_padded[:, :-2]) & (x >= x_padded[:, 2:])  # note: x > x_left && x >= x_right\n",
    "    x_padded = tf.pad(x, paddings=[[0, 0], [3, 3]])  # use wider receptive field, note: x == x_padded[:, 3:-3]\n",
    "    mask = (x > x_padded[:, :-6]) & (x > x_padded[:, 2:-4]) & (x >= x_padded[:, 4:-2]) & (x >= x_padded[:, 6:])  # note: x > x_left && x >= x_right\n",
    "    mask = tf.cast(mask, dtype=x.dtype)\n",
    "\n",
    "    # Apply indices and mask to inputs\n",
    "    x = inputs\n",
    "    x = tf.gather_nd(x, indices)\n",
    "    x = x * mask\n",
    "    return x\n",
    "\n",
    "class ZoneSorting(k_layers.Layer):\n",
    "  def __init__(self, zone, num_tracks=num_tracks, **kwargs):\n",
    "    super(ZoneSorting, self).__init__(**kwargs)\n",
    "    self.zone = zone\n",
    "    self.num_tracks = num_tracks\n",
    "\n",
    "    # Embedding\n",
    "    # See: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "    w_init = 'zeros'  #FIXME\n",
    "    embedding_kwargs = dict(input_dim=num_embedding_input_dim, output_dim=1, input_length=1,\n",
    "                            embeddings_initializer=w_init, trainable=False)\n",
    "    self.embedding = k_layers.Embedding(**embedding_kwargs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Embedding\n",
    "    x = inputs\n",
    "    x = self.embedding(x)\n",
    "    x = tf.reduce_sum(x, axis=-1)  # NWY -> NW, Y is dim of size 1\n",
    "\n",
    "    # Max elements\n",
    "    indices = tf.argsort(x, axis=-1, direction='DESCENDING', stable=True)\n",
    "    indices = indices[:, :self.num_tracks]\n",
    "    indices_0 = tf.tile(tf.expand_dims(tf.range(tf.shape(indices)[0]), axis=-1), multiples=(1, self.num_tracks))\n",
    "    indices = tf.stack([indices_0, indices], axis=-1)\n",
    "\n",
    "    # Apply indices to inputs\n",
    "    x = inputs\n",
    "    x = tf.gather_nd(x, indices)\n",
    "    return x\n",
    "\n",
    "class ZoneMerging(k_layers.Layer):\n",
    "  def __init__(self, num_tracks=num_tracks, **kwargs):\n",
    "    super(ZoneMerging, self).__init__(**kwargs)\n",
    "    self.num_tracks = num_tracks\n",
    "\n",
    "    # Embedding\n",
    "    # See: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "    w_init = 'zeros'  #FIXME\n",
    "    embedding_kwargs = dict(input_dim=num_embedding_input_dim, output_dim=1, input_length=1,\n",
    "                            embeddings_initializer=w_init, trainable=False)\n",
    "    self.embedding = k_layers.Embedding(**embedding_kwargs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Embedding\n",
    "    x = inputs\n",
    "    x = self.embedding(x)\n",
    "    x = tf.reduce_sum(x, axis=-1)  # NWY -> NW, Y is dim of size 1\n",
    "\n",
    "    # Max elements\n",
    "    indices = tf.argsort(x, axis=-1, direction='DESCENDING', stable=True)\n",
    "    indices = indices[:, :self.num_tracks]\n",
    "    indices_0 = tf.tile(tf.expand_dims(tf.range(tf.shape(indices)[0]), axis=-1), multiples=(1, self.num_tracks))\n",
    "    indices = tf.stack([indices_0, indices], axis=-1)\n",
    "\n",
    "    # Apply indices to inputs\n",
    "    x = inputs\n",
    "    x = tf.gather_nd(x, indices)\n",
    "    return x\n",
    "\n",
    "class TrackBuilding(k_layers.Layer):\n",
    "  def __init__(self, num_track_variables=num_track_variables, **kwargs):\n",
    "    super(TrackBuilding, self).__init__(**kwargs)\n",
    "    self.num_track_variables = num_track_variables\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Expand dim\n",
    "    indices = tf.zeros_like(inputs, dtype=tf.int32)\n",
    "    indices_0 = tf.expand_dims(tf.expand_dims(tf.range(tf.shape(indices)[0]), axis=-1), axis=-1)\n",
    "    indices_0 = tf.tile(indices_0, multiples=(1, indices.shape[1], self.num_track_variables))\n",
    "    indices_1 = tf.expand_dims(tf.expand_dims(tf.range(indices.shape[1]), axis=0), axis=-1)\n",
    "    indices_1 = tf.tile(indices_1, multiples=(tf.shape(indices)[0], 1, self.num_track_variables))\n",
    "    indices = tf.stack([indices_0, indices_1], axis=-1)\n",
    "\n",
    "    # Apply indices to inputs\n",
    "    x = inputs\n",
    "    x = tf.gather_nd(x, indices)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  # Input\n",
    "  inputs = keras.Input(shape=(num_emtf_chambers, num_emtf_segments, num_emtf_variables), name='inputs')\n",
    "  x = inputs\n",
    "\n",
    "  # Loop over zones\n",
    "  x_list = []\n",
    "\n",
    "  for i in range(num_emtf_zones):\n",
    "    # Make zone images\n",
    "    x_i = Zoning(zone=i, name='zoning_{0}'.format(i))(x)\n",
    "\n",
    "    # Pattern recognition\n",
    "    x_i = Pooling(zone=i, name='pooling_{0}'.format(i))(x_i)\n",
    "    x_i = Erosion(zone=i, name='erosion_{0}'.format(i))(x_i)\n",
    "\n",
    "    # Zone sorter\n",
    "    x_i = ZoneSorting(zone=i, name='zone_sorting_{0}'.format(i))(x_i)\n",
    "\n",
    "    # Add x_i to x_list\n",
    "    x_list.append(x_i)\n",
    "\n",
    "  # Merge zone outputs\n",
    "  x = k_layers.Concatenate(axis=-1)(x_list)\n",
    "  x = ZoneMerging(name='zone_merging')(x)\n",
    "\n",
    "  # Track builder\n",
    "  x = TrackBuilding(name='track_building'.format(i))(x)\n",
    "\n",
    "  # Output\n",
    "  outputs = x\n",
    "\n",
    "  # Model\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs, name='awesome_model')\n",
    "\n",
    "  # Summary\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"awesome_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 115, 8, 8)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zoning_0 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_1 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zoning_2 (Zoning)               (None, 8, 288, 1)    0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pooling_0 (Pooling)             (None, 288, 7)       6272        zoning_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_1 (Pooling)             (None, 288, 7)       6272        zoning_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooling_2 (Pooling)             (None, 288, 7)       6272        zoning_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "erosion_0 (Erosion)             (None, 288)          2048        pooling_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "erosion_1 (Erosion)             (None, 288)          2048        pooling_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "erosion_2 (Erosion)             (None, 288)          2048        pooling_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zone_sorting_0 (ZoneSorting)    (None, 4)            2048        erosion_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zone_sorting_1 (ZoneSorting)    (None, 4)            2048        erosion_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zone_sorting_2 (ZoneSorting)    (None, 4)            2048        erosion_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 12)           0           zone_sorting_0[0][0]             \n",
      "                                                                 zone_sorting_1[0][0]             \n",
      "                                                                 zone_sorting_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zone_merging (ZoneMerging)      (None, 4)            2048        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "track_building (TrackBuilding)  (None, 4, 36)        0           zone_merging[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 33,152\n",
      "Trainable params: 0\n",
      "Non-trainable params: 33,152\n",
      "__________________________________________________________________________________________________\n",
      "trainable weights: 0\n",
      "all weights: 13\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "print('trainable weights:', len(model.trainable_weights))\n",
    "print('all weights:', len(model.weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] outputs: (10, 4, 36) type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "\n",
    "logger.info('outputs: {0} type: {1}'.format(outputs.shape, type(outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: (10, 8, 288, 1) type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(array([0, 1, 2, 3, 4, 5, 5, 6, 6, 7]), array([127, 129, 132, 140, 140, 143, 149, 142, 153, 144]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(array([0, 2, 3, 4, 5, 6, 7]), array([264, 263, 257, 256, 254, 253, 253]), array([0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "model_zoning_0 = keras.Model(inputs=model.input,\n",
    "                             outputs=model.get_layer('zoning_0').output)\n",
    "outputs = model_zoning_0(inputs)\n",
    "print('outputs: {0} type: {1}'.format(outputs.shape, type(outputs)))\n",
    "\n",
    "if isinstance(outputs, tf.Tensor):\n",
    "  x = outputs.numpy()\n",
    "else:\n",
    "  x = outputs\n",
    "\n",
    "with np.printoptions(linewidth=100, threshold=1000):\n",
    "  print(x[0].nonzero())\n",
    "  print(x[2].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: (10, 288, 7) type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(array([  0,   0,   0, ..., 287, 287, 287]), array([1, 2, 3, ..., 4, 5, 6]))\n",
      "(array([  0,   0,   0, ..., 287, 287, 287]), array([1, 2, 3, ..., 4, 5, 6]))\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "model_pooling_0 = keras.Model(inputs=model.input,\n",
    "                              outputs=model.get_layer('pooling_0').output)\n",
    "outputs = model_pooling_0(inputs)\n",
    "print('outputs: {0} type: {1}'.format(outputs.shape, type(outputs)))\n",
    "\n",
    "if isinstance(outputs, tf.Tensor):\n",
    "  x = outputs.numpy()\n",
    "else:\n",
    "  x = outputs\n",
    "\n",
    "with np.printoptions(linewidth=100, threshold=1000):\n",
    "  print(x[0].nonzero())\n",
    "  print(x[2].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: (10, 288) type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(array([ 93,  97, 140]),) [1030. 1542. 1528.]\n",
      "(array([230, 237, 248, 255]),) [1030. 1286. 1310. 1532.]\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "model_erosion_0 = keras.Model(inputs=model.input,\n",
    "                              outputs=model.get_layer('erosion_0').output)\n",
    "outputs = model_erosion_0(inputs)\n",
    "print('outputs: {0} type: {1}'.format(outputs.shape, type(outputs)))\n",
    "\n",
    "if isinstance(outputs, tf.Tensor):\n",
    "  x = outputs.numpy()\n",
    "else:\n",
    "  x = outputs\n",
    "\n",
    "with np.printoptions(linewidth=100, threshold=1000):\n",
    "  print(x[0].nonzero(), x[0][x[0].nonzero()])\n",
    "  print(x[2].nonzero(), x[2][x[2].nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
